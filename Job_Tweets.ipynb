{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a36889-8019-4c0d-a82a-ba06591d5879",
   "metadata": {},
   "source": [
    "### Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318ae09-a1f0-47ff-af86-71e45dd0aaa1",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING: <br>\n",
    "1. Noise Reduction --> remove noise such as punctuation, special characters, and irrelevant symbols\n",
    "2. Normalization --> standardize variations for different form of words that can convey same meaning\n",
    "3. Tokenization --> broken down text data into smaller units such as words or phrases\n",
    "4. Stopword Removal --> removal stopword such as \"the\", \"is\", \"and\"\n",
    "5. Feature Selection -->  extracting features from text for building machine learning models\n",
    "6. Dimensionality Reduction --> transformation of text data from a high-dimensional space into a low-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b983db4-babe-485e-b73f-8a28c134b6b8",
   "metadata": {},
   "source": [
    "The `absa_model` and `absa_tokenizer` to test the `deberta-v3-base-abas-v1.1 pre-trained ABSA model`.\n",
    "The `sentiment_model` to test a standard sentiment model (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26712e53-2a19-4a09-9563-f451af411c85",
   "metadata": {},
   "source": [
    "Importing related libraries and read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78267ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d210da3d-47cd-4b89-b9fc-9eddb4608aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830c5905-2db8-4b98-b290-4c844eb6dd95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1211798864656769025</td>\n",
       "      <td>2019-12-30 23:58:58+00:00</td>\n",
       "      <td>SipapuNM</td>\n",
       "      <td>Looking for an exciting job where you can ski ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>20 miles SE of Taos, NM</td>\n",
       "      <td>False</td>\n",
       "      <td>3342</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "0  1211798864656769025  2019-12-30 23:58:58+00:00         SipapuNM   \n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Looking for an exciting job where you can ski ...   \n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "0                                                NaN         0      1   \n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "0        0  <a href=\"http://instagram.com\" rel=\"nofollow\">...   \n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \n",
       "0    20 miles SE of Taos, NM             False       3342        258  \n",
       "1                    Arizona             False         63        129  \n",
       "2                 Texas, USA             False         19         50  \n",
       "3  Orange County, California             False        966       1569  \n",
       "4              United States             False        983       1251  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Job_Tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53acd564-955c-48a8-b53b-e43cf6857ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Timestamp',\n",
       " 'User',\n",
       " 'Text',\n",
       " 'Hashtag',\n",
       " 'Retweets',\n",
       " 'Likes',\n",
       " 'Replies',\n",
       " 'Source',\n",
       " 'Location',\n",
       " 'Verified_Account',\n",
       " 'Followers',\n",
       " 'Following']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all column names in the dataset\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "172262e2-df40-4bfe-b494-69e88aad1a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the dataset:\n",
      "Number of rows: 50000\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "# to check dimensions of the dataset\n",
    "print(\"Dimensions of the dataset:\")\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dddd3a44-c134-4727-a7c5-8d6ac05d240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of data types and non-null values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ID                50000 non-null  int64 \n",
      " 1   Timestamp         50000 non-null  object\n",
      " 2   User              50000 non-null  object\n",
      " 3   Text              50000 non-null  object\n",
      " 4   Hashtag           40684 non-null  object\n",
      " 5   Retweets          50000 non-null  int64 \n",
      " 6   Likes             50000 non-null  int64 \n",
      " 7   Replies           50000 non-null  int64 \n",
      " 8   Source            50000 non-null  object\n",
      " 9   Location          44011 non-null  object\n",
      " 10  Verified_Account  50000 non-null  bool  \n",
      " 11  Followers         50000 non-null  int64 \n",
      " 12  Following         50000 non-null  int64 \n",
      "dtypes: bool(1), int64(6), object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# to get a summary of data types and non-null values\n",
    "print(\"Summary of data types and non-null values:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932a5863-a1c7-467c-8ec4-aac2c1e7f909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  object\n",
       "Timestamp           object\n",
       "User                object\n",
       "Text                object\n",
       "Hashtag             object\n",
       "Retweets             int64\n",
       "Likes                int64\n",
       "Replies              int64\n",
       "Source              object\n",
       "Location            object\n",
       "Verified_Account      bool\n",
       "Followers            int64\n",
       "Following            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data type of user ID from int to object\n",
    "df[\"ID\"] = df[\"ID\"].astype(object)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dba699-5801-470e-bca7-2e4cd0785ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics for numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.692100</td>\n",
       "      <td>1.347860</td>\n",
       "      <td>0.108920</td>\n",
       "      <td>5.511382e+03</td>\n",
       "      <td>1961.965460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.441484</td>\n",
       "      <td>17.527216</td>\n",
       "      <td>1.276483</td>\n",
       "      <td>6.770825e+04</td>\n",
       "      <td>5847.789338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.980000e+02</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.258000e+03</td>\n",
       "      <td>1076.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1677.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>5.226473e+06</td>\n",
       "      <td>310791.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Retweets         Likes       Replies     Followers      Following\n",
       "count  50000.000000  50000.000000  50000.000000  5.000000e+04   50000.000000\n",
       "mean       0.692100      1.347860      0.108920  5.511382e+03    1961.965460\n",
       "std        7.441484     17.527216      1.276483  6.770825e+04    5847.789338\n",
       "min        0.000000      0.000000      0.000000  0.000000e+00       0.000000\n",
       "25%        0.000000      0.000000      0.000000  8.000000e+01      94.000000\n",
       "50%        0.000000      0.000000      0.000000  2.980000e+02     331.000000\n",
       "75%        0.000000      0.000000      0.000000  1.258000e+03    1076.000000\n",
       "max     1016.000000   1677.000000    175.000000  5.226473e+06  310791.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to calculate the basic statistics for numerical columns\n",
    "print(\"Basic statistics for numerical columns:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e7eec8-ad2e-4a86-9d53-81125451a111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>40684</td>\n",
       "      <td>50000</td>\n",
       "      <td>44011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50000</td>\n",
       "      <td>46795</td>\n",
       "      <td>13715</td>\n",
       "      <td>46507</td>\n",
       "      <td>14227</td>\n",
       "      <td>261</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1636315580528574467</td>\n",
       "      <td>2019-12-19 20:00:27+00:00</td>\n",
       "      <td>cameroncraig</td>\n",
       "      <td>We generally enjoy and are satisfied by being ...</td>\n",
       "      <td>['hiring', 'jobs', 'Houston']</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2513</td>\n",
       "      <td>134</td>\n",
       "      <td>792</td>\n",
       "      <td>21888</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID                  Timestamp          User  \\\n",
       "count                 50000                      50000         50000   \n",
       "unique                50000                      46795         13715   \n",
       "top     1636315580528574467  2019-12-19 20:00:27+00:00  cameroncraig   \n",
       "freq                      1                          8          2513   \n",
       "\n",
       "                                                     Text  \\\n",
       "count                                               50000   \n",
       "unique                                              46507   \n",
       "top     We generally enjoy and are satisfied by being ...   \n",
       "freq                                                  134   \n",
       "\n",
       "                              Hashtag  \\\n",
       "count                           40684   \n",
       "unique                          14227   \n",
       "top     ['hiring', 'jobs', 'Houston']   \n",
       "freq                              792   \n",
       "\n",
       "                                                   Source       Location  \n",
       "count                                               50000          44011  \n",
       "unique                                                261           5973  \n",
       "top     <a href=\"http://www.ziprecruiter.com\" rel=\"nof...  United States  \n",
       "freq                                                21888           3504  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing categorical data\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe714ff0-bbcc-41db-93d0-ad60936b35a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "ID                     0\n",
      "Timestamp              0\n",
      "User                   0\n",
      "Text                   0\n",
      "Hashtag             9316\n",
      "Retweets               0\n",
      "Likes                  0\n",
      "Replies                0\n",
      "Source                 0\n",
      "Location            5989\n",
      "Verified_Account       0\n",
      "Followers              0\n",
      "Following              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to check for any missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db5a17d-fad4-4ea1-ab0e-0d257b0c27b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "ID                  0\n",
      "Timestamp           0\n",
      "User                0\n",
      "Text                0\n",
      "Hashtag             0\n",
      "Retweets            0\n",
      "Likes               0\n",
      "Replies             0\n",
      "Source              0\n",
      "Location            0\n",
      "Verified_Account    0\n",
      "Followers           0\n",
      "Following           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.dropna()\n",
    "df = missing_values\n",
    "missing_values = df.isnull().sum() # count number of missing values again\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e06ddb-d05a-4ddb-9569-a6b91fef1782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "         ...  \n",
       "49993    False\n",
       "49995    False\n",
       "49996    False\n",
       "49997    False\n",
       "49998    False\n",
       "Length: 36632, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to identify any duplicated rows in the dataset\n",
    "duplicate_rows = df.duplicated()\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b5f671-59fb-4117-836a-4135735245bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# to count the number of duplicated rows\n",
    "num_duplicates = sum(duplicate_rows)\n",
    "print(num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb7ef43-03f4-4619-9574-2bda4969ca1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ID:\n",
      "[1211797371853705220 1211795775363145728 1211793355060981767 ...\n",
      " 1636306593858871297 1636305111726141440 1636304982768066561]\n",
      "\n",
      "Unique values in Timestamp:\n",
      "['2019-12-30 23:53:02+00:00' '2019-12-30 23:46:41+00:00'\n",
      " '2019-12-30 23:37:04+00:00' ... '2023-03-16 10:01:07+00:00'\n",
      " '2023-03-16 09:55:14+00:00' '2023-03-16 09:54:43+00:00']\n",
      "\n",
      "Unique values in User:\n",
      "['LorettaOD1' 'guajardo_celina' 'SteveEckert_OTD' ... 'movmn'\n",
      " 'babelsblessing' 'SSARecruit']\n",
      "\n",
      "Unique values in Text:\n",
      "['Hail in Phoenix - no way!  New opportunity at Freedom? Possibly. We are hiring a(n) Reconciliation Specialist II and would like to talk to you!\\nhttps://t.co/CFAKKQHeFJ #job'\n",
      " 'Rackspace is hiring! We are looking for National Partner Manager. Learn more or Jobvite a friend. #becomearacker #Rackspace #recruiting #talentacquisition #jobsearching\\nhttps://t.co/XuSMG0eSgs #job'\n",
      " 'We are #hiring Administrative Assistant in Nanuet, NY https://t.co/3IGxFiCXUI #jobs #Nanuet'\n",
      " ...\n",
      " \"A lovely review from one of our wonderful candidates 💕\\n\\nIt's heart-warming reviews like this, that make us love our jobs even more, as we are here to make a difference ✨\\n\\n#SSADigital #Recruitment #Hiring #Review https://t.co/En3UQHu7GO\"\n",
      " 'We are #hiring Automotive Service Advisor Writer in Grayling, MI https://t.co/r52DOaqMRS #jobs #Grayling'\n",
      " 'We are #hiring Automotive Sales Consultant in Grayling, MI https://t.co/FsVlBkNmmd #jobs #Grayling']\n",
      "\n",
      "Unique values in Hashtag:\n",
      "[\"['job']\"\n",
      " \"['becomearacker', 'Rackspace', 'recruiting', 'talentacquisition', 'jobsearching', 'job']\"\n",
      " \"['hiring', 'jobs', 'Nanuet']\" ...\n",
      " \"['hiring', 'jobs', 'vacancy', 'jobsearch']\"\n",
      " \"['projectcoordinator', 'london', 'jobs']\"\n",
      " \"['SSADigital', 'Recruitment', 'Hiring', 'Review']\"]\n",
      "\n",
      "Unique values in Retweets:\n",
      "[  0   1   4   8   3   2  15   5   6   7  11  55   9 120  12  19  16  47\n",
      "  17  33  37  13  10  23  20  89  22  25  38  14  21  72  63  27 223  28\n",
      "  24  42  39  32  34  43  54  26 119 142 151  48 718 154  18 338  36  77]\n",
      "\n",
      "Unique values in Likes:\n",
      "[   0    1    2   13    3   11    6    4    5   24    7    8   18   25\n",
      "   47   10    9   12   19  101   14   20   41   45  174   38   16   26\n",
      "   31   28   37   15  112   22   51   39   17   90   77  119   55  126\n",
      "   23   59   49  338   32   35   71   52   27   44   50   30   54   29\n",
      "   96   36   34  125  105   21  140  377  618   57   72   48 1285   64\n",
      "   43   68  198   33  870  440   67  334  165  162   40]\n",
      "\n",
      "Unique values in Replies:\n",
      "[  0   1   2   3   8   4  37   5  21   7  12  11  24  10  72  19  15  39\n",
      "  29  18   6  44 175  26  49  20   9  14]\n",
      "\n",
      "Unique values in Source:\n",
      "['<a href=\"http://jobvite.com\" rel=\"nofollow\">Jobvite</a>'\n",
      " '<a href=\"http://www.ziprecruiter.com\" rel=\"nofollow\">ZipRecruiter Post Jobs</a>'\n",
      " '<a href=\"http://instagram.com\" rel=\"nofollow\">Instagram</a>'\n",
      " '<a href=\"https://social.zoho.com\" rel=\"nofollow\">Zoho Social</a>'\n",
      " '<a href=\"https://www.mightyrecruiter.com\" rel=\"nofollow\">MightyRecruiter</a>'\n",
      " '<a href=\"https://dlvrit.com/\" rel=\"nofollow\">dlvr.it</a>'\n",
      " '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'\n",
      " '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>'\n",
      " '<a href=\"https://buffer.com\" rel=\"nofollow\">Buffer</a>'\n",
      " '<a href=\"https://www.hootsuite.com\" rel=\"nofollow\">Hootsuite Inc.</a>'\n",
      " '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>'\n",
      " '<a href=\"http://www.hubspot.com/\" rel=\"nofollow\">HubSpot</a>'\n",
      " '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
      " '<a href=\"https://vacancymail.co.zw/\" rel=\"nofollow\">VacancyMail</a>'\n",
      " '<a href=\"http://www.linkedin.com/\" rel=\"nofollow\">LinkedIn</a>'\n",
      " '<a href=\"https://app.planable.io\" rel=\"nofollow\">Planable</a>'\n",
      " '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>'\n",
      " '<a href=\"http://www.servisourcejobs.com\" rel=\"nofollow\">Servisource Jobs</a>'\n",
      " '<a href=\"https://app.socialpilot.co/\" rel=\"nofollow\">SocialPilot.co</a>'\n",
      " '<a href=\"https://fanbooster.com\" rel=\"nofollow\">Fanbooster by Traject</a>'\n",
      " '<a href=\"https://sproutsocial.com\" rel=\"nofollow\">Sprout Social</a>'\n",
      " '<a href=\"https://app.sendible.com\" rel=\"nofollow\">Sendible</a>'\n",
      " '<a href=\"https://ifttt.com\" rel=\"nofollow\">IFTTT</a>'\n",
      " '<a href=\"https://www.socialoomph.com\" rel=\"nofollow\">SocialOomph</a>'\n",
      " '<a href=\"https://app.agorapulse.com\" rel=\"nofollow\">Agorapulse app</a>'\n",
      " '<a href=\"https://naukrilatest.com\" rel=\"nofollow\">NaukriLatest.com</a>'\n",
      " '<a href=\"http://postplanner.com\" rel=\"nofollow\">Post Planner LLC</a>'\n",
      " '<a href=\"https://zapier.com/\" rel=\"nofollow\">Zapier.com</a>'\n",
      " '<a href=\"http://pardot.com\" rel=\"nofollow\">Pardot</a>'\n",
      " '<a href=\"https://postcron.com\" rel=\"nofollow\">Postcron App</a>'\n",
      " '<a href=\"https://www.loomly.com/\" rel=\"nofollow\">Loomly</a>'\n",
      " '<a href=\"https://trac.systems\" rel=\"nofollow\">Trac Jobs</a>'\n",
      " '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>'\n",
      " '<a href=\"https://www.heyorca.com\" rel=\"nofollow\">HeyOrca</a>'\n",
      " '<a href=\"http://www.salesforce.com\" rel=\"nofollow\">Salesforce - Social Studio</a>'\n",
      " '<a href=\"https://www.semrush.com/\" rel=\"nofollow\">Semrush Social Media Tool</a>'\n",
      " '<a href=\"http://workfor.us/jobboard\" rel=\"nofollow\">Work For Us</a>'\n",
      " '<a href=\"https://coschedule.com\" rel=\"nofollow\">CoSchedule</a>'\n",
      " '<a href=\"https://www.meltwater.com/\" rel=\"nofollow\">Meltwater Social</a>'\n",
      " '<a href=\"https://lightful.com\" rel=\"nofollow\">Lightful</a>'\n",
      " '<a href=\"https://ads.twitter.com\" rel=\"nofollow\">Twitter Ads</a>'\n",
      " '<a href=\"https://eclincher.com\" rel=\"nofollow\">eClincher</a>'\n",
      " '<a href=\"https://www.later.com\" rel=\"nofollow\">LaterMedia</a>'\n",
      " '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>'\n",
      " '<a href=\"https://www.getjobs.com\" rel=\"nofollow\">GetJobsZw</a>'\n",
      " '<a href=\"https://ads-api.twitter.com\" rel=\"nofollow\">Twitter for Advertisers.</a>'\n",
      " '<a href=\"http://twibble.io\" rel=\"nofollow\">Twibble.io</a>'\n",
      " '<a href=\"http://www.oneupapp.io\" rel=\"nofollow\">OneUp App</a>'\n",
      " '<a href=\"https://github.com/dudewith3faces\" rel=\"nofollow\">abothasnoface</a>'\n",
      " '<a href=\"http://www.falcon.io\" rel=\"nofollow\">Brandwatch</a>'\n",
      " '<a href=\"https://smarterqueue.com\" rel=\"nofollow\">SmarterQueue</a>'\n",
      " '<a href=\"http://dynamicsignal.com/\" rel=\"nofollow\">Dynamic Signal</a>'\n",
      " '<a href=\"http://www.example.com\" rel=\"nofollow\">Mr. Advisor</a>'\n",
      " '<a href=\"https://www.just.jobs\" rel=\"nofollow\">Just Dot Jobs</a>'\n",
      " '<a href=\"http://www.adicio.com/\" rel=\"nofollow\">Social Distribution</a>'\n",
      " '<a href=\"https://contentstudio.io\" rel=\"nofollow\">ContentStudio.io</a>'\n",
      " '<a href=\"http://publicize.wp.com/\" rel=\"nofollow\">Jetpack.com</a>'\n",
      " '<a href=\"http://socialfive.com\" rel=\"nofollow\">Social5</a>'\n",
      " '<a href=\"https://twitter.facelift-cloud.com/\" rel=\"nofollow\">Facelift-Cloud</a>'\n",
      " '<a href=\"https://www.oktopost.com\" rel=\"nofollow\">Oktopost</a>'\n",
      " '<a href=\"https://studio.twitter.com\" rel=\"nofollow\">Twitter Media Studio</a>'\n",
      " '<a href=\"https://www.ripl.com\" rel=\"nofollow\">Ripl App</a>'\n",
      " '<a href=\"http://usjobsandcareers.com/\" rel=\"nofollow\">US Jobs and Careers</a>'\n",
      " '<a href=\"https://www.relevantjobs.com/\" rel=\"nofollow\">Relevant Jobs Poster</a>'\n",
      " '<a href=\"https://www.spredfast.com\" rel=\"nofollow\">Khoros Publishing App</a>'\n",
      " '<a href=\"http://social.icims.com\" rel=\"nofollow\">iCIMS Social Distribution</a>'\n",
      " '<a href=\"https://adobe.com/express\" rel=\"nofollow\">Adobe Express (old)</a>'\n",
      " '<a href=\"http://directory.engineeringdaily.net\" rel=\"nofollow\">Engineering Daily </a>'\n",
      " '<a href=\"http://hearsaysystems.com\" rel=\"nofollow\">Hearsay Social</a>'\n",
      " '<a href=\"https://prod1.sprinklr.com\" rel=\"nofollow\">Sprinklr Publishing</a>'\n",
      " '<a href=\"http://www.universelisting.com\" rel=\"nofollow\">Free Classifieds</a>'\n",
      " '<a href=\"http://itunes.apple.com/us/app/twitter/id409789998?mt=12\" rel=\"nofollow\">Twitter for Mac</a>'\n",
      " '<a href=\"https://publer.io\" rel=\"nofollow\">Publer.io</a>'\n",
      " '<a href=\"https://www.spredfast.com/\" rel=\"nofollow\">Khoros Publishing</a>'\n",
      " '<a href=\"https://metricool.com\" rel=\"nofollow\">Metricool</a>'\n",
      " '<a href=\"http://www.socialflow.com\" rel=\"nofollow\">SocialFlow</a>'\n",
      " '<a href=\"https://ifsocial.com/\" rel=\"nofollow\">ifSocial - Deliver Media</a>'\n",
      " '<a href=\"https://www.sprinklr.com/\" rel=\"nofollow\">Powered by Sprinklr</a>'\n",
      " '<a href=\"https://twitter.com\" rel=\"nofollow\">Twitter for Advertisers</a>'\n",
      " '<a href=\"https://www.campaign3.com\" rel=\"nofollow\">Campaign Share</a>'\n",
      " '<a href=\"https://app.socialhub.io/\" rel=\"nofollow\">SocialHub by maloon</a>'\n",
      " '<a href=\"https://CampaignDirector.myconnectwise.net\" rel=\"nofollow\">ConnectWise CampaignDirector</a>'\n",
      " '<a href=\"https://www.canva.com\" rel=\"nofollow\">Canva</a>'\n",
      " '<a href=\"https://revive.social/\" rel=\"nofollow\">Revive Social App</a>'\n",
      " '<a href=\"http://www.socialbakers.com/\" rel=\"nofollow\">Emplifi</a>'\n",
      " '<a href=\"https://zlappo.com\" rel=\"nofollow\">Zlappo.com</a>'\n",
      " '<a href=\"https://dashboard.godaddy.com\" rel=\"nofollow\">GoDaddy Social App</a>'\n",
      " '<a href=\"https://www.tweetedtimes.com\" rel=\"nofollow\">The Tweeted Times</a>'\n",
      " '<a href=\"https://prod2.sprinklr.com\" rel=\"nofollow\">Sprinklr Publisher</a>'\n",
      " '<a href=\"https://moa.party\" rel=\"nofollow\">Moa Bridge</a>'\n",
      " '<a href=\"http://www.boxwoodtech.com\" rel=\"nofollow\">CareerCenter</a>'\n",
      " '<a href=\"https://sociality.io/\" rel=\"nofollow\">Sociality.io</a>'\n",
      " '<a href=\"https://www.sprinklr.com\" rel=\"nofollow\">Sprinklr</a>'\n",
      " '<a href=\"https://www.meetsoci.com\" rel=\"nofollow\">SOCi </a>'\n",
      " '<a href=\"https://www.rssground.com\" rel=\"nofollow\">RSS Ground</a>'\n",
      " '<a href=\"https://www.contentmx.com\" rel=\"nofollow\">ContentMX</a>'\n",
      " '<a href=\"https://www.sharpspring.com\" rel=\"nofollow\">Constant Contact - LeadGen&CRM</a>'\n",
      " '<a href=\"https://promo.com\" rel=\"nofollow\">Promo.com</a>'\n",
      " '<a href=\"https://conte.ai\" rel=\"nofollow\">Conte.ai</a>'\n",
      " '<a href=\"https://www.blog2social.com\" rel=\"nofollow\">Blog2Social APP</a>'\n",
      " '<a href=\"http://www.rallio.com\" rel=\"nofollow\">Rallio</a>'\n",
      " '<a href=\"https://www.tumblr.com/\" rel=\"nofollow\">Tumblr</a>'\n",
      " '<a href=\"https://app.clearviewsocial.com\" rel=\"nofollow\">Clearview Social, Inc.</a>'\n",
      " '<a href=\"https://soampli.com/\" rel=\"nofollow\">SoAmpli App</a>'\n",
      " '<a href=\"https://orlo.tech\" rel=\"nofollow\">Orlo</a>'\n",
      " '<a href=\"https://metigy.com/\" rel=\"nofollow\">Metigy</a>'\n",
      " '<a href=\"http://crowdcontrolhq.com/\" rel=\"nofollow\">SoCrowd</a>'\n",
      " '<a href=\"https://www.planoly.com\" rel=\"nofollow\">PLANOLY</a>'\n",
      " '<a href=\"http://www.mailchimp.com\" rel=\"nofollow\">Mailchimp</a>'\n",
      " '<a href=\"https://www.make.com\" rel=\"nofollow\">Make (formerly Integromat)</a>'\n",
      " '<a href=\"http://erased22638509_oR8JEhR2LM.com\" rel=\"nofollow\">erased22638509_oR8JEhR2LM</a>'\n",
      " '<a href=\"https://www.grapevine6.com\" rel=\"nofollow\">LiveSocial Regulated</a>'\n",
      " '<a href=\"https://paiger.co\" rel=\"nofollow\">Paiger 2</a>'\n",
      " '<a href=\"https://socialbee.com/\" rel=\"nofollow\">SocialBee</a>'\n",
      " '<a href=\"http://gainapp.com\" rel=\"nofollow\">Gain Platform</a>'\n",
      " '<a href=\"https://www.constantcontact.com/\" rel=\"nofollow\">Constant Contact - Social Posts</a>'\n",
      " '<a href=\"https://twitter.com\" rel=\"nofollow\">TweetDeck Web App</a>'\n",
      " '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">BismarckApp</a>'\n",
      " '<a href=\"https://www.echobox.com\" rel=\"nofollow\">Echobox</a>'\n",
      " '<a href=\"https://dynamics.microsoft.com\" rel=\"nofollow\">Dynamics 365 for Marketing</a>'\n",
      " '<a href=\"http://www.reputationmailer.com/privacy/\" rel=\"nofollow\">Social Reputation</a>'\n",
      " '<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for iΟS</a>'\n",
      " '<a href=\"http://travelmediagroup.com\" rel=\"nofollow\">TMG-OneView</a>'\n",
      " '<a href=\"http://storychief.io\" rel=\"nofollow\">Story Chief</a>'\n",
      " '<a href=\"http://meetedgar.com\" rel=\"nofollow\">MeetEdgar</a>'\n",
      " '<a href=\"https://dashboard.heropost.io/\" rel=\"nofollow\">Heropost</a>'\n",
      " '<a href=\"http://www.powerapps.com\" rel=\"nofollow\">Microsoft Power Platform</a>'\n",
      " '<a href=\"https://socialpost.cc/\" rel=\"nofollow\">SocialPost App</a>'\n",
      " '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">paghdjobs</a>'\n",
      " '<a href=\"https://amplifr.com\" rel=\"nofollow\">Amplifr</a>'\n",
      " '<a href=\"http://platform.social\" rel=\"nofollow\">SocialModo</a>'\n",
      " '<a href=\"https://www.willow.co\" rel=\"nofollow\">Willow Social Media</a>'\n",
      " '<a href=\"http://www.socialnewsdesk.com\" rel=\"nofollow\">SocialNewsDesk</a>'\n",
      " '<a href=\"https://promorepublic.com\" rel=\"nofollow\">PromoRepublic</a>'\n",
      " '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">growremotely</a>'\n",
      " '<a href=\"http://smarp.com\" rel=\"nofollow\">Smarp.</a>'\n",
      " '<a href=\"https://refari.co/\" rel=\"nofollow\">Refari</a>'\n",
      " '<a href=\"http://slacksocial.com\" rel=\"nofollow\">SlackSocial</a>'\n",
      " '<a href=\"https://postly.ai\" rel=\"nofollow\">Postly Social</a>'\n",
      " '<a href=\"https://cloudcampaign.io/\" rel=\"nofollow\">Cloud Campaign</a>'\n",
      " '<a href=\"http://www.everyonesocial.com\" rel=\"nofollow\">EveryoneSocial</a>'\n",
      " '<a href=\"https://ingoedebanen.nl/\" rel=\"nofollow\">Vacatures via InGoedeBanen.nl</a>'\n",
      " '<a href=\"https://jainsusa.com/\" rel=\"nofollow\">Jain Irrigation USA</a>'\n",
      " '<a href=\"https://stocktwits.com\" rel=\"nofollow\">StockTwits Web</a>'\n",
      " '<a href=\"https://zobjobs.com\" rel=\"nofollow\">zUS2</a>'\n",
      " '<a href=\"https://zobjobs.com\" rel=\"nofollow\">zGB2</a>'\n",
      " '<a href=\"https://www.hopperhq.com/\" rel=\"nofollow\">Hopper HQ</a>'\n",
      " '<a href=\"https://pipedream.com\" rel=\"nofollow\">Pipedream, Inc</a>'\n",
      " '<a href=\"http://www.careerarc.com\" rel=\"nofollow\">CareerArc App</a>'\n",
      " '<a href=\"https://www.careerarc.com\" rel=\"nofollow\">CareerArc 2.0</a>'\n",
      " '<a href=\"https://r4e-social-oauth.reputation.com/\" rel=\"nofollow\">Reputation.com-Social</a>'\n",
      " '<a href=\"https://flamepost.com\" rel=\"nofollow\">FlamePost</a>'\n",
      " '<a href=\"https://netsocialapp.com\" rel=\"nofollow\">NetSocialApp</a>'\n",
      " '<a href=\"https://zobjobs.com\" rel=\"nofollow\">zCA2</a>'\n",
      " '<a href=\"https://www.arubaito.io\" rel=\"nofollow\">arubaito_job_poster</a>'\n",
      " '<a href=\"https://crowdfireapp.com\" rel=\"nofollow\">Crowdfire App</a>'\n",
      " '<a href=\"http://www.coosto.com\" rel=\"nofollow\">Coosto</a>'\n",
      " '<a href=\"http://www.khaltura.com/\" rel=\"nofollow\">khaltura.com</a>'\n",
      " '<a href=\"https://paiger.co\" rel=\"nofollow\">Paiger</a>'\n",
      " '<a href=\"https://www.mustakbil.com\" rel=\"nofollow\">Mustakbil</a>'\n",
      " '<a href=\"https://www.thryv.com/\" rel=\"nofollow\">Thryv</a>'\n",
      " '<a href=\"https://www.radaar.io/\" rel=\"nofollow\">RADAAR</a>'\n",
      " '<a href=\"http://postbeyond.com\" rel=\"nofollow\">PostBeyond</a>'\n",
      " '<a href=\"https://www.kontentino.com\" rel=\"nofollow\">Kontentino</a>'\n",
      " '<a href=\"https://workforcenow.adp.com/workforcenow/login.html\" rel=\"nofollow\">WorkForceNow</a>'\n",
      " '<a href=\"http://www.greenhouse.io\" rel=\"nofollow\">Greenhouse.io</a>'\n",
      " '<a href=\"https://getbambu.com\" rel=\"nofollow\">Advocacy by Sprout Social</a>'\n",
      " '<a href=\"https://www.wearehiring.io\" rel=\"nofollow\">wearehiring</a>'\n",
      " '<a href=\"https://hiplayapp.com\" rel=\"nofollow\">Hiplay</a>'\n",
      " '<a href=\"https://www.fs-poster.com\" rel=\"nofollow\">GT Auto-Poster</a>'\n",
      " '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">MeetAlfred</a>'\n",
      " '<a href=\"https://pallyy.com\" rel=\"nofollow\">Pallyy</a>'\n",
      " '<a href=\"https://simplified.com\" rel=\"nofollow\">Simplified One App</a>'\n",
      " '<a href=\"https://recurpost.com\" rel=\"nofollow\">recurpost.com</a>'\n",
      " '<a href=\"https://zymplify.com\" rel=\"nofollow\">Zymplify</a>'\n",
      " '<a href=\"http://erased8155444_R6xFGhObhn.com\" rel=\"nofollow\">erased8155444_R6xFGhObhn</a>'\n",
      " '<a href=\"https://dev-senalysis.spillover.com\" rel=\"nofollow\">Senalysis-dev</a>'\n",
      " '<a href=\"https://apptegy.com\" rel=\"nofollow\">Thrillshare</a>'\n",
      " '<a href=\"https://www.socialchamp.io\" rel=\"nofollow\">SocialChamp IO </a>'\n",
      " '<a href=\"https://www.ocoya.net\" rel=\"nofollow\">Ocoya</a>'\n",
      " '<a href=\"https://vistasocial.com\" rel=\"nofollow\">Vista Social</a>'\n",
      " '<a href=\"https://app.scompler.com/\" rel=\"nofollow\">Scompler</a>'\n",
      " '<a href=\"https://twittimer.com\" rel=\"nofollow\">Twittimer</a>'\n",
      " '<a href=\"https://skedsocial.com\" rel=\"nofollow\">Sked Social</a>']\n",
      "\n",
      "Unique values in Location:\n",
      "['Arizona' 'Texas, USA' 'Orange County, California' ... 'Täby' 'Italia'\n",
      " 'Innovation Centre, Silverstone']\n",
      "\n",
      "Unique values in Verified_Account:\n",
      "[False  True]\n",
      "\n",
      "Unique values in Followers:\n",
      "[   63    19   966 ... 28006  2173  6533]\n",
      "\n",
      "Unique values in Following:\n",
      "[ 129   50 1569 ... 1864 6476 6254]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to display unique values in each column to identify categorical variables\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in {column}:\")\n",
    "    print(unique_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcf688-487d-4f77-9a02-7d3a41404b9d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee2b8fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "310e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ac00646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip uninstall numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d9f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.0\n",
    "#pip install scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a33e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcf5d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.path.append(\"C:\\\\nltk_data\")  # Manually set the NLTK data path\n",
    "nltk.download('stopwords', download_dir=\"C:\\\\nltk_data\")\n",
    "nltk.download('punkt', download_dir=\"C:\\\\nltk_data\")\n",
    "nltk.download('wordnet', download_dir=\"C:\\\\nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e75a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Rasyiqah\n",
      "[nltk_data]     Rais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Rasyiqah\n",
      "[nltk_data]     Rais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Rasyiqah\n",
      "[nltk_data]     Rais\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73131454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Noise Reduction\n",
    "def remove_noise(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters, punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1789b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalization: Lowercasing & Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    words = nltk.word_tokenize(text)  # Tokenize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize words\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60386c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenization (Already integrated in Normalization)\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09f9d563",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Rasyiqah Rais/nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Apply all preprocessing steps to the 'text' column (adjust column name if needed)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your column name\u001b[39;00m\n\u001b[0;32m     17\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text):\n\u001b[0;32m     10\u001b[0m     text \u001b[38;5;241m=\u001b[39m remove_noise(text)\n\u001b[1;32m---> 11\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m remove_stopwords(text)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mnormalize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_text\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()  \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     words \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]  \u001b[38;5;66;03m# Lemmatize words\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Rasyiqah Rais/nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Rasyiqah Rais\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 4. Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply Preprocessing to the Dataset\n",
    "def preprocess_text(text):\n",
    "    text = remove_noise(text)\n",
    "    text = normalize_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "# Apply all preprocessing steps to the 'text' column (adjust column name if needed)\n",
    "df['cleaned_text'] = df['Text'].apply(preprocess_text)  # Replace with your column name\n",
    "df[['Text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e36981d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cleaned_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 5. Feature Selection: Convert text to numerical features\u001b[39;00m\n\u001b[0;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)  \u001b[38;5;66;03m# Limit to top 500 features\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tfidf_features \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-IDF feature extraction complete. Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tfidf_features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text'"
     ]
    }
   ],
   "source": [
    "# 5. Feature Selection: Convert text to numerical features\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Limit to top 500 features\n",
    "tfidf_features = vectorizer.fit_transform(df['cleaned_text'])\n",
    "print(\"TF-IDF feature extraction complete. Shape:\", tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a66de63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 6. Dimensionality Reduction using TruncatedSVD\u001b[39;00m\n\u001b[0;32m      2\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Reduce to 100 dimensions\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mtfidf_features\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensionality Reduction complete. Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, reduced_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Final preprocessed dataframe\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_features' is not defined"
     ]
    }
   ],
   "source": [
    "# 6. Dimensionality Reduction using TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100)  # Reduce to 100 dimensions\n",
    "reduced_features = svd.fit_transform(tfidf_features)\n",
    "print(\"Dimensionality Reduction complete. Shape:\", reduced_features.shape)\n",
    "\n",
    "# Final preprocessed dataframe\n",
    "df_features = pd.DataFrame(reduced_features, columns=[f'component_{i}' for i in range(1, 101)])\n",
    "print(\"\\nFinal reduced features:\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d652e4d-3b6d-4ba1-abda-b7b0abbb7d72",
   "metadata": {},
   "source": [
    "### Data Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b2410-80eb-4f3b-8578-7c12acd62bc2",
   "metadata": {},
   "source": [
    "Install and import related libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63b54f44-b1cc-48dd-ba3d-e15ee275fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61a4c3b7-e814-475a-ba72-715e0b8596f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed0c16e-c892-42ef-a35a-dc7205df8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d660c66d-90a7-4ca1-8cb1-7cb860441364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03a9d646-3024-4130-9de1-c75cdd4134f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8ba0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf_keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tf_keras) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rasyiqah rais\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rasyiqah rais\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.6.0)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rasyiqah rais\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rasyiqah rais\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 23.2 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 7.1/15.6 MB 31.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.6 MB 30.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 27.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, tf_keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.0\n",
      "    Uninstalling numpy-2.2.0:\n",
      "      Successfully uninstalled numpy-2.2.0\n",
      "Successfully installed numpy-2.0.2 tf_keras-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-smaller-training-vocab 0.4.0 requires numpy<2.0.0,>=1.21.0; python_version >= \"3.9\", but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tf_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e4ed4-3788-4ac1-bcdc-3e64e1f844f7",
   "metadata": {},
   "source": [
    "Installations are successful. Now, let's proceed to do sentiment analysis using TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c8b571-c384-4f1e-b7d7-1f4945f064fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tweepy\n",
    "import torch\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24627c8-4c69-4f63-98cd-38709680a3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...\n",
       "2  Rackspace is hiring! We are looking for Nation...\n",
       "3  We are #hiring Administrative Assistant in Nan...\n",
       "4  We are #hiring Family Service Counselor in Irv...\n",
       "5  We are #hiring Inside Sales Representative in ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting column 'Text' to do sentiment analysis and display in DataFrame\n",
    "df_text = pd.DataFrame(df['Text'])\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7838b-f4c9-4930-b8a7-1682e065161e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46aa2d1-080f-47b3-8edd-9357a0fcae56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>text_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \\\n",
       "1                    Arizona             False         63        129   \n",
       "2                 Texas, USA             False         19         50   \n",
       "3  Orange County, California             False        966       1569   \n",
       "4              United States             False        983       1251   \n",
       "5              United States             False        983       1251   \n",
       "\n",
       "                                   text_blob  \n",
       "1  (0.06818181818181818, 0.7272727272727273)  \n",
       "2                                 (0.5, 0.5)  \n",
       "3                                 (0.0, 0.0)  \n",
       "4                                 (0.0, 0.0)  \n",
       "5                                 (0.0, 0.0)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying TextBlob\n",
    "df['text_blob'] = df['Text'].apply(lambda x: TextBlob(x).sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abf29837-ac85-4aa0-a3e5-98606fd0f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text_blob\n",
       "1  (0.06818181818181818, 0.7272727272727273)\n",
       "2                                 (0.5, 0.5)\n",
       "3                                 (0.0, 0.0)\n",
       "4                                 (0.0, 0.0)\n",
       "5                                 (0.0, 0.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_blob = pd.DataFrame(df['text_blob'])\n",
    "df_text_blob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c9f104-3e51-4ec5-a810-1808b1674f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                   text_blob  \n",
       "1  (0.06818181818181818, 0.7272727272727273)  \n",
       "2                                 (0.5, 0.5)  \n",
       "3                                 (0.0, 0.0)  \n",
       "4                                 (0.0, 0.0)  \n",
       "5                                 (0.0, 0.0)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing 'Text' and text_blob side by side\n",
    "blob_analysis = df[['Text','text_blob']]\n",
    "blob_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315adb77-5322-444c-ab4d-df977d0d3bcb",
   "metadata": {},
   "source": [
    "<br> Let's do sentiment analysis using Vader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a132d726-b65f-4f56-9f34-ad0b5fcb096c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>text_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \\\n",
       "1                    Arizona             False         63        129   \n",
       "2                 Texas, USA             False         19         50   \n",
       "3  Orange County, California             False        966       1569   \n",
       "4              United States             False        983       1251   \n",
       "5              United States             False        983       1251   \n",
       "\n",
       "                                   text_blob  \\\n",
       "1  (0.06818181818181818, 0.7272727272727273)   \n",
       "2                                 (0.5, 0.5)   \n",
       "3                                 (0.0, 0.0)   \n",
       "4                                 (0.0, 0.0)   \n",
       "5                                 (0.0, 0.0)   \n",
       "\n",
       "                                          text_vader  \n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...  \n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Vader\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['text_vader'] = df['Text'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cf36fc4-cdb1-4005-a445-b220cba52211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_vader\n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...\n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...\n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_vader = pd.DataFrame(df['text_vader'])\n",
    "df_text_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e7cec5e-7782-47ac-a106-b0d4af79a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                          text_vader  \n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...  \n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing 'Text' and text_vader side by side\n",
    "vader_analysis = df[['Text','text_vader']]\n",
    "vader_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590404f",
   "metadata": {},
   "source": [
    "Let's do sentiment analysis using flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede3bef2-5db6-4d9d-b5e5-180ae711e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:15:45,316 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to C:\\Users\\RASYIQ~1\\AppData\\Local\\Temp\\tmpejencaa9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253M/253M [00:16<00:00, 15.9MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:16:02,913 copying C:\\Users\\RASYIQ~1\\AppData\\Local\\Temp\\tmpejencaa9 to cache at C:\\Users\\Rasyiqah Rais\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-14 16:16:03,386 removing temp file C:\\Users\\RASYIQ~1\\AppData\\Local\\Temp\\tmpejencaa9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>text_vader</th>\n",
       "      <th>text_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \\\n",
       "1                    Arizona             False         63        129   \n",
       "2                 Texas, USA             False         19         50   \n",
       "3  Orange County, California             False        966       1569   \n",
       "4              United States             False        983       1251   \n",
       "5              United States             False        983       1251   \n",
       "\n",
       "                                   text_blob  \\\n",
       "1  (0.06818181818181818, 0.7272727272727273)   \n",
       "2                                 (0.5, 0.5)   \n",
       "3                                 (0.0, 0.0)   \n",
       "4                                 (0.0, 0.0)   \n",
       "5                                 (0.0, 0.0)   \n",
       "\n",
       "                                          text_vader text_flair  \n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...   NEGATIVE  \n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...   POSITIVE  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE  \n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying flair\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "sentences = [Sentence(text) for text in df['Text']]\n",
    "classifier.predict(sentences)\n",
    "df['text_flair'] = [sentence.labels[0].value for sentence in sentences]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a3eace0-7f6e-4e1d-8caf-92070d1be454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_flair\n",
       "1   NEGATIVE\n",
       "2   POSITIVE\n",
       "3   NEGATIVE\n",
       "4   NEGATIVE\n",
       "5   NEGATIVE"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_flair = pd.DataFrame(df['text_flair'])\n",
    "df_text_flair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4d72e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text text_flair\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   NEGATIVE\n",
       "2  Rackspace is hiring! We are looking for Nation...   POSITIVE\n",
       "3  We are #hiring Administrative Assistant in Nan...   NEGATIVE\n",
       "4  We are #hiring Family Service Counselor in Irv...   NEGATIVE\n",
       "5  We are #hiring Inside Sales Representative in ...   NEGATIVE"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing 'Text' and text_flair side by side\n",
    "flair_analysis = df[['Text','text_flair']]\n",
    "flair_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1bf54",
   "metadata": {},
   "source": [
    "Let's do sentiment analysis using Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "914d1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>text_vader</th>\n",
       "      <th>text_flair</th>\n",
       "      <th>text_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \\\n",
       "1                    Arizona             False         63        129   \n",
       "2                 Texas, USA             False         19         50   \n",
       "3  Orange County, California             False        966       1569   \n",
       "4              United States             False        983       1251   \n",
       "5              United States             False        983       1251   \n",
       "\n",
       "                                   text_blob  \\\n",
       "1  (0.06818181818181818, 0.7272727272727273)   \n",
       "2                                 (0.5, 0.5)   \n",
       "3                                 (0.0, 0.0)   \n",
       "4                                 (0.0, 0.0)   \n",
       "5                                 (0.0, 0.0)   \n",
       "\n",
       "                                          text_vader text_flair text_bert  \n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...   NEGATIVE    1 star  \n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...   POSITIVE   5 stars  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars  \n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Transformers\n",
    "sentiment_model = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "def analyze_sentiment(text):\n",
    "    result = sentiment_model(text)\n",
    "    return result[0]['label']\n",
    "\n",
    "df['text_bert'] = df['Text'].apply(analyze_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98fe4b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_bert\n",
       "1    1 star\n",
       "2   5 stars\n",
       "3   5 stars\n",
       "4   5 stars\n",
       "5   5 stars"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_bert = pd.DataFrame(df['text_bert'])\n",
    "df_text_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6096f6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>1 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text text_bert\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...    1 star\n",
       "2  Rackspace is hiring! We are looking for Nation...   5 stars\n",
       "3  We are #hiring Administrative Assistant in Nan...   5 stars\n",
       "4  We are #hiring Family Service Counselor in Irv...   5 stars\n",
       "5  We are #hiring Inside Sales Representative in ...   5 stars"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing 'Text' and text_transformers side by side\n",
    "bert_analysis = df[['Text','text_bert']]\n",
    "bert_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ccbd33",
   "metadata": {},
   "source": [
    "Let's do sentiment analysis with DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ce14905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>text_vader</th>\n",
       "      <th>text_flair</th>\n",
       "      <th>text_bert</th>\n",
       "      <th>text_distilbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "      <td>(0.06818181818181818, 0.7272727272727273)</td>\n",
       "      <td>{'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>1 star</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "\n",
       "                                                Text  \\\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \\\n",
       "1                    Arizona             False         63        129   \n",
       "2                 Texas, USA             False         19         50   \n",
       "3  Orange County, California             False        966       1569   \n",
       "4              United States             False        983       1251   \n",
       "5              United States             False        983       1251   \n",
       "\n",
       "                                   text_blob  \\\n",
       "1  (0.06818181818181818, 0.7272727272727273)   \n",
       "2                                 (0.5, 0.5)   \n",
       "3                                 (0.0, 0.0)   \n",
       "4                                 (0.0, 0.0)   \n",
       "5                                 (0.0, 0.0)   \n",
       "\n",
       "                                          text_vader text_flair text_bert  \\\n",
       "1  {'neg': 0.062, 'neu': 0.618, 'pos': 0.32, 'com...   NEGATIVE    1 star   \n",
       "2  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...   POSITIVE   5 stars   \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars   \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars   \n",
       "5  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   NEGATIVE   5 stars   \n",
       "\n",
       "  text_distilbert  \n",
       "1         LABEL_1  \n",
       "2         LABEL_1  \n",
       "3         LABEL_1  \n",
       "4         LABEL_1  \n",
       "5         LABEL_1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying DistilBERT\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased\", device=-1) \n",
    "df['text_distilbert'] = classifier(df['Text'].tolist(), truncation=True, max_length=512)\n",
    "df['text_distilbert'] = df['text_distilbert'].apply(lambda x: x['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f5584fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_distilbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_distilbert\n",
       "1         LABEL_1\n",
       "2         LABEL_1\n",
       "3         LABEL_1\n",
       "4         LABEL_1\n",
       "5         LABEL_1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_distilbert = pd.DataFrame(df['text_distilbert'])\n",
    "df_text_distilbert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89577e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_distilbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>LABEL_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text text_distilbert\n",
       "1  Hail in Phoenix - no way!  New opportunity at ...         LABEL_1\n",
       "2  Rackspace is hiring! We are looking for Nation...         LABEL_1\n",
       "3  We are #hiring Administrative Assistant in Nan...         LABEL_1\n",
       "4  We are #hiring Family Service Counselor in Irv...         LABEL_1\n",
       "5  We are #hiring Inside Sales Representative in ...         LABEL_1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing 'Text' and text_distilbert side by side\n",
    "distilbert_analysis = df[['Text','text_distilbert']]\n",
    "distilbert_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc19719",
   "metadata": {},
   "source": [
    "Let's do Aspect-Based Sentiment Analysis (ABSA) using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e227b075",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "yangheng/deberta-v3-base-absa is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/yangheng/deberta-v3-base-absa/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 277\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 301\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m     )\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-675d6f7f-6a52ded74f4d57995d3c81a3;4058f869-6ff6-44b1-a49c-136a3c6db872)\n\nRepository Not Found for url: https://huggingface.co/yangheng/deberta-v3-base-absa/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[1;32m----> 3\u001b[0m absa_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myangheng/deberta-v3-base-absa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m absa_tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myangheng/deberta-v3-base-absa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_absa\u001b[39m(text, aspect):\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:487\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Rasyiqah Rais\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: yangheng/deberta-v3-base-absa is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained('yangheng/deberta-v3-base-absa')\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained('yangheng/deberta-v3-base-absa')\n",
    "\n",
    "def perform_absa(text, aspect):\n",
    "    inputs = absa_tokenizer(f\"{aspect}: {text}\", return_tensors='pt')\n",
    "    outputs = absa_model(**inputs)\n",
    "    sentiment = torch.argmax(outputs.logits, dim=1).item()\n",
    "    if sentiment == 0:\n",
    "        return 'negative'\n",
    "    elif sentiment == 1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "# Perform ABSA for 'job' aspect\n",
    "df['text_absa'] = df['Text'].apply(lambda x: perform_absa(x, 'job'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_absa = pd.DataFrame(df['text_absa'])\n",
    "df_text_absa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a74bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing 'Text' and text_absa side by side\n",
    "absa_analysis = df[['Text','text_absa']]\n",
    "absa_analysis.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
